# Conditional Probability and Expectation {#probability}

```{r include=FALSE}
library(dplyr, quietly = TRUE)
library(boot, quietly = TRUE)
```


```{r include=FALSE}
# the directory of documentation for chapter 1
dir_docs01 <- file.path(dirname(getwd()), "FundamentalsCausalInference_docs",
                   "Brumback FOCI Website Material", "Chapter 1")
# directory of data files
dir_data <- file.path(getwd(), "data")
# directory for functions
dir_lib <- file.path(getwd(), "lib")
```


```{r include=FALSE}
source(file = file.path(dir_lib, "boot_utils.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "fci_01-A_mortability.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "fci_02-A_sim.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "fci_02-B_lmodboot.R"), 
       local = knitr::knit_global())
load(file.path(dir_docs01, "whatifdat.RData"))
load(file.path(dir_docs01, "nces.RData"))
```



The mortality data was given in chapter 1, section 1.2.1.

```{r}
dataMortality <- data_mortability()
```


## Conditional Probability


### Law of total probability

It is important to note that $\sum_i{H_i} = H$, that is $H$ can be partitioned 
in $i$ non-overlapping partitions.

Then the law of total probabilities is

$$
\begin{align*}
P(A) &= \sum_i{P(A \cap H_i)}= \sum_i{P(A \mid H_i) P(H_i)} \\
&\text{and we condition the whole expression with B} \\
P(A \mid B) &= \sum_i{P(A \cap H_i \mid B)}= \sum_i{P(A \mid B, H_i) P(B,H_i)} \\
\end{align*}
$$

and the multiplication rule is


$$
\begin{align*}
P(A, B \mid C) &= \frac{P(A, B, C)}{P(C)} \\
&= \frac{P(A \mid B, C) P(B, C)}{P(C)} \\
&= \frac{P(A \mid B, C) P(B \mid C) P(C)}{P(C)} \\
&= P(A \mid B, C) P(B \mid C)
\end{align*}
$$



## Conditional Expectation and the Law of Total expectation

The function `expit()` used by the author is actually the same as
`gtools::inv.logit()`, `boot::inv.logit()` or `stats::plogis()`. In this project 
we use `stats::plogis()` because it is in base R and we want to minimize
dependencies.

## Estimation

Using the *What-if* example we have

$$
\begin{align*}
X_i \beta &= X_{i,1} \beta_i +\ldots+X_{i, p}\beta_p \\
&\therefore \\
X_i \beta &= \beta_1 A_i + \beta_2 T_i + \beta_3 H_i \\
\end{align*}
$$

and 

$$
X_i^T(Y_i - X_i \beta) \\
\therefore \\
\begin{bmatrix}
1 \cdot(Y_i - \beta_1 - A_i \beta_2 - T_i \beta_3 - H_i \beta_4) \\
A_i \cdot(Y_i - \beta_1 - A_i \beta_2 - T_i \beta_3 - H_i \beta_4) \\
T_i \cdot(Y_i - \beta_1 - A_i \beta_2 - T_i \beta_3 - H_i \beta_4)\\
H_i \cdot(Y_i - \beta_1 - A_i \beta_2 - T_i \beta_3 - H_i \beta_4)
\end{bmatrix}
$$



## Sampling Distributions and the Bootstrap


```{r echo=FALSE, file="lib\\fci_02-A_sim.R"}

```


Run and verify with author's results on p. 32


```{r}
d <- sim(nsim = 500, n = 500)
stopifnot(abs(d$bad - 0.8374) < 0.03, 
          abs(d$good - 0.948) < 0.03)
d
```


```{r echo=TRUE, file="lib\\fci_02-B_lmodboot.R"}

```


Run and verify against the author's results on p.34

```{r}
d <- lmodboot(whatifdat, R = 500)
d
# check results with book
stopifnot(abs(d["est"] - 0.60596) < 0.02,
          abs(d["lci"] - 0.41638) < 0.02,
          abs(d["uci"] - 0.76823) < 0.02)
```


## Exercises

The exercises are located in a separate project.
