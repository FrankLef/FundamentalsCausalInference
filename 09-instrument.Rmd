# Instrumental Variables {#instrument}


```{r echo=TRUE, message=FALSE, warning=FALSE}
library(rsample)
library(dplyr)
library(ggdag)
library(patchwork)
library(ggplot2)
library(fciR)
options(dplyr.summarise.inform = FALSE)
```



```{r include=FALSE}
# directory of data files
dir_data <- file.path(getwd(), "data")
# directory for functions
dir_lib <- file.path(getwd(), "lib")
```



```{r echo=FALSE, warning=FALSE}
scm_9.1 <- list()
scm_9.1 <- within(scm_9.1, {
  coords <- list(
    x = c(`T` = 1, A = 2, U = 3, Y = 4),
    y = c(`T` = 1, A = 1, U = 2, Y = 1))
  dag <- dagify(
    A ~ `T` + U,
    Y ~ A + U,
    coords = coords)

  plot <- fciR::ggp_dag(dag)
})
```

```{r echo=FALSE, fig.align='center', fig.cap="Instrumental Variable for the Effect of A on Y", out.width="60%"}
scm_9.1$plot
```


> We enlist the following notation for this chapter. Let $Y(t,a)$ be the 
potential outcome for $Y$ assuming we set $T=t$ and then $A=a$.

* We assume consistency $E(Y(t) \mid T=t)= E(Y \mid T=t$)
* We assume exclusion $Y(t,a)=Y(a)$

Lets say that participants to treatment $T$ may comply or not and let $A$ be 
the treatment actually taken. That is $A=1$ means that the treatment was taken
by the participant. $A$ is therefore a post-randomization event.

When $A$ does not equal $T$ there is 2 historical methods:

1. *as-treated*: Compare $E(Y \mid A=1) with $E(Y \mid A=0)
2. *per-protocol*: We let $Z=1$ if $A=T$ and use ordinary stratification on
$Z=1$ to compare $E(Y \mid T=1, Z=1)$ with $E(Y \mid T=0, Z=1)$

$Z=1$ is not a randomization event since it uses observed measurements
after they occur. As a result $Z$ *cannot be expected to balance across 2 
treatments groups*. For example sicker patients could alwyas comply but healthy
ones might. In thsi case we have $T=1, A=1$ for the sicker patient but the healthy
patients would be a mix of $T=1, A-1$ and $T=1, A=0$.

> For these reasons, many studies rely on the *intent-to-treat effect* (ITT)
$E(Y \mid T=1) - E(Y \mid T=0)$. This equates to the causal effect

$$
ITT = E(Y(1,A(1))) -  E(Y, A(0, 0)))
$$


## Complier Average Causal Effect and Principal Stratification

### Principal Stratification

> Principal stratification classifies participants according to the potential 
occurence of a *post-randomization event*. We define 4 principal strata of 
participants according tottheir potential outcome $A(t)$.

1. *never-taker*: $A(0)=A(1)=0$. Will not take the treatment regardless of
randomized assignment.
2. *always-taker*: $A(0)=A(1)=1$. Will not take the treatment regardless of
randomized assignment.
3. *complier*: $A(0)=0, A(1)=1$, i.e. $A(t)=t$. Will take the treatment as 
required.
4. *defier*: $A(0)=1, A(1)=0$, i.e. $A(t)=1-t$. Will refuse to take the 
treatment as required.

Let $C$ indicate a complier, i.e. that $A(t)=t$. Then since

(a) $T$ is a randomized, i.e. $Y \perp\!\!\!\perp T \mid C$
(b) $C$ is a pre-randomization variable, i.e. $T \perp\!\!\!\perp C$
(c) $Y(t,a) = Y(a)$

it is reasonable to assume

$$
Y(a) \perp\!\!\!\perp T \mid C
$$

### Complier Average Causal Effect

The *complier average causal effect* (CACE) is defined as the average effect of 
treatment (ATT) in the compliers. That is

$$
\begin{align*}
CACE &= E(Y(1) \mid C=1) - E(Y(0) \mid C=1) \\
&= E(Y \mid T=1, C=1) - E(Y \mid T=0, C=1)
\end{align*}
$$

The equation shows CACE as a stratified treatment effct, but $C=1$ defines a
principal stratum instead of an ordinary one.

We can estimate CACE assuming exclusion and *no defiers*. Assuming no defiers implies

$$
E(Y \mid T=1, C=0) = E(Y \mid T=0, C=0)
$$

because no defiers implies that $C=0$ includes only *never-takers* and 
*always-takers* and these 2 groups act the same way regardless of what $T$ is. 
In addition, exclusion ensures that randomization of $T$ cannot affect
the outcome of the never-takers and always-takers since $Y \perp\!\!\!\perp T \mid A$.

The, **assuming no defierss** we can say the

$$
E(Y \mid T=1) = E(Y \mid T=1, C=1)P(C=1) + E(Y \mid T=1, C=0)(1-P(C=1))
$$
and

$$
E(Y \mid T=0) = E(Y \mid T=0, C=1)P(C=1) + E(Y \mid T=0, C=0)(1-P(C=1))
$$
and therefore

$$
\begin{align*}
E(Y \mid T=1) - E(Y \mid T=0) &= E(Y \mid T=1, C=1)P(C=1) + E(Y \mid T=1, C=0)(1-P(C=1)) - \left[ E(Y \mid T=0, C=1)P(C=1) + E(Y \mid T=0, C=0)(1-P(C=1)) \right] \\
\frac{E(Y \mid T=1) - E(Y \mid T=0)}{P(C=1)} &= E(Y \mid T=1, C=1) + \frac{E(Y \mid T=1, C=0)}{P(C=1)} - E(Y \mid T=1, C=0) - \left[ E(Y \mid T=0, C=1) + 
\frac{E(Y \mid T=0, C=0)}{P(C=1)} - E(Y \mid T=0, C=0) \right] \\
\end{align*}
$$
and since from above we know that


$$
E(Y \mid T=1, C=0) = E(Y \mid T=0, C=0)
$$

then


$$
\begin{align*}
\frac{E(Y \mid T=1) - E(Y \mid T=0)}{P(C=1)} = E(Y \mid T=1, C=1) - E(Y \mid T=1, C=0)
\end{align*}
$$

and to find $P(C=1)$ since *we assume no defiers* then we know that


$$
P(C=1) + P(A=0 \mid T=1) + P(A=1 \mid T=0) = 1
$$

and therefore

$$
\begin{align*}
&\text{assuming no defiers} \\
P(C=1) &= 1 - P(A=0 \mid T=1) + P(A=1 \mid T=0) \\
&= P(A=1 \mid T=1) + P(A=1 \mid T=0)
\end{align*}
$$
and putting it together we obtain


$$
\begin{align*}
\text{CACE} &= E(Y \mid T=1, C=1) - E(Y \mid T=1, C=0) \\
&= \frac{E(Y \mid T=1) - E(Y \mid T=0)}{P(A=1 \mid T=1) + P(A=1 \mid T=0)} \\
&= \frac{ITT}{P(A=1 \mid T=1) + P(A=1 \mid T=0)}
\end{align*}
$$
## Average Effect of Treatment on the Treated and Structural Nested mean Models

> A drawback of the CACE is that it applies only to the compliers, a subgroup 
of the populaiton that we cannot even identify.

Another way to do it is to use the average effect of treatment on the treated

$$
\text{ATT} = E(Y(1) - Y(0) \mid A=1) = E(Y - Y(0) \mid A=1)
$$

> To estimate the ATT using the instrumental variable, $T$, we introduce
structural nested mean models.

The linear structural nested mean model is

$$
E(Y - Y(0) \mid A, T) = A \beta
$$

$Y-Y(0)$ is assumed to be mean indedendent of $T$ given $A$. Thsi therefore 
implies that there is no defiers as they create a dependency on $T$. It also
implies that *any effect modifiers of $Y-Y(0)$ is balanced across $T=0$ and 
$T=1$ groups.

The non-causal linear model is using $D$ which is a function of $A$ and $T$

$$
E(Y \mid A,T)=D \eta
$$

therefore

$$
D \eta - A \beta = E(Y(0) \mid A, T)
$$
and so

$$
E_{A \mid T} (D \eta - A \beta) = E(Y(0) \mid A, T)
$$

The solution for $\eta$ is found using the method of chapter 2, section 2.3.

$$
\sum_{n=1}^n (1,T_i)^T(D_i \hat{\eta} -A_i \beta - \alpha) = 0
$$

and for $\alpha$ and $\beta$ we use instrumental variable regression which can 
be done with the `ivreg` function from the package $AER$.


$$
\sum_{n=1}^n (1,T_i)^T(Y_i^* - A_i^* \beta - \alpha) = 0
$$

## Examples

### What-If Study

```{r}
data("whatifdat", package = "fciR")
whatif <- whatifdat
round(prop.table(xtabs(data = whatif, formula = ~ `T` + A), margin = 1), 2)
rm(whatifdat)
```
and the  function as found on p. 164 is modified to allow the bootstrapping
with many iterations by setting IV to `NA` where the denominator is too small.

```{r}
instr_vars <- function(data, outcome.name = "Y", exposure.name = "A",
                       instrument.name = "T", tol = .Machine$double.eps^0.5) {
  
  # estimate the ITT
  dat0 <- data[, instrument.name] == 0
  dat1 <- data[, instrument.name] == 1
  ITT <- mean(data[dat1, outcome.name]) - mean(data[dat0, outcome.name])
  
  # estimate the denominator of the CAE and ATT with equation (9.5)
  denom <- mean(data[dat1, exposure.name]) - mean(data[dat0, exposure.name])
  # denominator should not be near zero to avoid numerical problems
  check <- abs(denom) >= tol
  if(check) {
    IV <- ITT / denom
  } else {
    IV <- NA_real_
  }
  c("ITT" = ITT, "IV" = IV)
  } 
```

with the results

```{r}
whatif.est <- instr_vars(whatif, outcome.name = "Y", exposure.name = "A", instrument.name = "T")
stopifnot(sum(abs(whatif.est - c(0.007352941, 0.27777778))) < .Machine$double.eps^0.5)
whatif.est
.Machine$double.eps^0.5

```

and using only 100 boots to estimate the CI

```{r}
whatif.out <- fciR::boot_est(
  whatif, instr_vars, R = 1000, conf = 0.95, inv = "none", outcome.name = "Y",
  exposure.name = "A", instrument.name = "T", tol = 1e-6) %>%
  mutate(across(.cols = where(is.numeric), .fns = round, digits = 4))
whatif.out
```

**Note:** Although we used 1000 iterations for bootstraping with `NA` when the 
denominator is too close to zero. It is more flexible than the code in the
book but **still with a lot of variability** for the CI of IV. In fact, in very 
many iterations, the CI were much wider than what the author calculated and most
of the time the CI was about `c(-30, 30)`.


### Double What-if Study

```{r}
data("doublewhatifdat", package = "fciR")
dwhatif <- doublewhatifdat
```


We compute the estimator for the linear, loglinear and logistic SNMM using
the Double What-If Study. The functions are in the `fciR` package and can be
consulted as usual by using `F2` on the function.

```{r}
dwhatif.lininstr <- fciR::instr_linear(dwhatif, outcome.name = "VL1",
                                       exposure.name = "A", 
                                       instrument.name = "T")
dwhatif.lininstr
```
and we bootstrap instead of using `jackknife`

```{r}
?jackknife
```


```{r}
# whatif.out <- fciR::boot_est(
#   dwhatif.lininstr, fciR::instr_linear, R = 10, conf = 0.95, inv = "none",
#   outcome.name = "VL1", exposure.name = "A", instrument.name = "T", tol = 1e-6)
# whatif.out
```



```{r}
data("fci_tbl_09_01", package = "fciR")
bb_dwhatif <- fci_tbl_09_01
bb_dwhatif
gt_measures_rowgrp(
    bb_dwhatif, 
    rowgroup = "name",
    rowname = "method",
    conf = 0.95,
    title = "Table 9.1", 
    subtitle = paste("Double What-If Study",
                     "Instrumental Variables Analysis",
                     sep = "<br>"))
```



