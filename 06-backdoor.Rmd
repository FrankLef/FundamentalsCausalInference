# Backdoor Method via Standardization {#backdoor}


```{r echo=TRUE, message=FALSE, warning=FALSE}
library(tidyr)
library(dplyr)
library(dagitty)
library(ggplot2)
library(ggdag)
library(gt)
library(geepack)
```



```{r include=FALSE}
# the directory of documentation for chapter 1
dir_docs01 <- file.path(dirname(getwd()), "FundamentalsCausalInference_docs",
                   "Brumback FOCI Website Material", "Chapter 1")
dir_docs03 <- file.path(dirname(getwd()), "FundamentalsCausalInference_docs",
                   "Brumback FOCI Website Material", "Chapter 3")
dir_docs06 <- file.path(dirname(getwd()), "FundamentalsCausalInference_docs",
                   "Brumback FOCI Website Material", "Chapter 6")
# directory of data files
dir_data <- file.path(getwd(), "data")
# directory for functions
dir_lib <- file.path(getwd(), "lib")
```


```{r message=FALSE, warning=FALSE, include=FALSE}
source(file = file.path(dir_lib, "boot_utils.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "gt_utils.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "gt_measures.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "fci_01-A_mortability.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "fci_01-B_doublewhatifsim.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "fci_06-A_stand.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "fci_06-B_standout.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "fci_06-C_exposure.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "fci_06-D_standexp.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "fci_06-E_standexpgee.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "fci_06-F_badstanddr.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "fci_06-G_mc_standdr.R"), 
       local = knitr::knit_global())
source(file = file.path(dir_lib, "fci_06-H_simdr.R"), 
       local = knitr::knit_global())
load(file.path(dir_docs01, "whatifdat.RData"))
load(file.path(dir_docs01, "gss.RData"))
load(file.path(dir_docs03, "brfss.RData"))
load(file.path(dir_docs06, "whatif2dat.RData"))
```


## Standardization via Outome Modeling

> Standardization vis via outcome modelingis one way to estimate $E(Y(t))$


$$
\begin{align*}
&\text{by double expectation theorem} \\
E(Y(t)) &= E_H E(Y(t) \mid H) \\
&\text{by independence of T given H, (6.1)} \\
&= E_HE(Y(t) \mid T=t, H) \\
&\text{by consistency assumption} \\
&= E_HE(Y \mid T=t, H)
\end{align*}
$$

and with a binary dataset we can write

$$
\begin{align*}
E_H E(Y \mid T=t, H) = E(Y \mid T=t, H = 0) P(H = 0) + E(Y \mid T=t, H = 1) P(H = 1)
\end{align*}
$$


We use `R` to compute the standardized estimates with the following script


```{r echo=TRUE, file="lib\\fci_06-A_stand.R"}

```


### Examples {-}

#### What-if? Study {-}

and for the What-If? study this gives


```{r}
whatif.out <- stand(whatifdat, formula = Y ~ A + H + A:H)
whatif.out
```

and we compare with the author's

```{r}
comp <- data.frame(
  name = c("EY0", "EY1", "RD", "RR"),
  auth = c(0.375, 0.289, -0.086, 0.77),
  est = whatif.out$est[whatif.out$name %in% c("EY0", "EY1", "RD", "RR")]
)
stopifnot(sum(abs(comp$auth - comp$est)) < 0.01)
```

and the results are presented in table 6.1

```{r}
gt_measures(whatif.out, 
            title = "Table 6.1", 
            subtitle = "What-If Study<br>Standardized Estimates")
```


where we observe a reduction of the viral load but the difference is not
statistically significant.


#### Double What-if? Study {-}


```{r}
dataDoubleWhatIf <- doublewhatifsim()
```


```{r}
doublewhatif.out <- stand(dataDoubleWhatIf, formula = VL1 ~ A + AD0 + A*AD0)
```


```{r}
gt_measures(doublewhatif.out, 
            title = "Table 6.2", 
            subtitle = "Double What-If Study<br>Standardized Estimates with <em>H = AD0</em>")
```



> For comparisons, we repeat the standardization with $H = VL_0$



```{r}
doublewhatif.out <- stand(dataDoubleWhatIf, formula = VL1 ~ A + VL0 + A*VL0)
```


```{r}
gt_measures(doublewhatif.out, 
            title = "Table 6.3", 
            subtitle = "Double What-If Study<br>Standardized Estimates with <em>H = VL0</em>")
```


### Average Effect of Treatment on the Treated


The function `bootstandatt` described in section 6.1.1 is not necessary,
see the function `bootstand` in the prious section which can do it with the 
addition of the argument `att`.


#### What-if? Study {-}


```{r}
whatif.att <- stand(whatifdat, formula = Y ~ A + H + A*H, att = TRUE)
```

and we compare with the author's

```{r}
comp <- data.frame(
  name = c("EY0", "EY1", "RD", "RR"),
  auth = c(0.361, 0.276, -0.085, 0.765),
  est = whatif.att$est[whatif.att$name %in% c("EY0", "EY1", "RD", "RR")]
)
stopifnot(sum(abs(comp$auth - comp$est)) < 0.01)
```

and the results are presented in table 6.1

```{r}
gt_measures(whatif.att, 
            title = "Table 6.4", 
            subtitle = "What-If Study<br>Standardized ATT estimates")
```
#### Double What-if? Study {-}



```{r}
doublewhatif.att <- stand(dataDoubleWhatIf, formula = VL1 ~ A + AD0 + A*AD0,
                              att = TRUE)
```


```{r}
gt_measures(doublewhatif.att, 
            title = "Table 6.5", 
            subtitle = "Double What-If Study<br>Standardized ATT Estimates with <em>H = AD0</em>")
```




```{r}
doublewhatif.att <- stand(dataDoubleWhatIf, formula = VL1 ~ A + VL0 + A*VL0,
                              att = TRUE)
```


```{r}
gt_measures(doublewhatif.att, 
            title = "Table 6.6", 
            subtitle = "Double What-If Study<br>Standardized ATT Estimates with <em>H = VL0</em>")
```

### Standardization with a Parametric Outcome Model

For a the parametric outcome model `standout` is used

```{r echo=TRUE, file="lib\\fci_06-B_standout.R"}

```


#### What-if? Study {-}

```{r}
whatif2.out <- standout(whatif2dat, formula = vl4 ~ A + lvlcont0)
# whatif2.out
```

and we compare with the author's

```{r}
comp <- data.frame(
  name = c("EY0", "EY1", "RD", "RR"),
  auth = c(0.360, 0.300, -0.061, 0.831),
  est = whatif2.out$est[whatif2.out$name %in% c("EY0", "EY1", "RD", "RR")]
)
# comp
stopifnot(sum(abs(comp$auth - comp$est)) < 0.01)
```

and the results are presented in table 6.1

```{r}
gt_measures(whatif2.out, 
            title = "Table 6.7", 
            subtitle = "What-If Study<br>Outome-model Standardization with <em>H = lvlcont0</ems>")
```

#### General Social Survey {-}

```{r}
gssrcc <- gss[, c("trump", "gthsedu", "magthsedu", "white", "female", "gt65")]
gssrcc <- gssrcc[complete.cases(gssrcc), ]
```





```{r}
message("This takes about 15 sec.. Load from file.")
# startTime <- Sys.time()
# gssrcc.out <- standout(gssrcc, 
#                         formula = trump ~ gthsedu + magthsedu + white + female + gt65)
# endTime <- Sys.time()
# print(endTime - startTime)
a_file <- file.path(dir_data, "chap06_gssrcc_out.rds")
# saveRDS(gssrcc.out, file = a_file)
gssrcc.out <- readRDS(file = a_file)
# gssrcc.out
```

and we compare with the author's

```{r}
comp <- data.frame(
  name = c("EY0", "EY1", "RD", "RR"),
  auth = c(0.233, 0.271, 0.038, 1.164),
  est = gssrcc.out$est[gssrcc.out$name %in% c("EY0", "EY1", "RD", "RR")]
)
stopifnot(sum(abs(comp$auth - comp$est)) < 0.01)
```

and the results are presented in table 6.8

```{r}
gt_measures(whatif2.out, 
            title = "Table 6.8", 
            subtitle = "General Social Survey<br>
            Outcome-model Standardization<br>
            Effect of <em>More than High School Education</em> on <em>
            Voting for Trump</em>")
```

## Standardization via Exposure Modeling

### Examples {-}

#### Mortality Rates by Country {-}

See section 1.2.1 in chapter 1 for details on `data_mortability_exp`.


```{r}
mortdat <- data_mortability_exp()
```


Compute the standardized estimates using exposure modeling with `calc_exposure`. 
The author puts the function it with the data itself. A better idea is to
put the logic in a function separate from the data.

```{r echo=TRUE, file="lib\\fci_06-C_exposure.R"}

```


```{r}
mortdat.out <- calc_exposure(mortdat, formula = Y ~ `T` + H, weights = "n")
mortdat.out[c("EY0", "EY1")]
# verify with the author's
stopifnot(abs(mortdat.out$EY0 - 0.0078399) < 1e-7,
          abs(mortdat.out$EY1 - 0.0069952) < 1e-7)
```



### Average Effect of Treatment on the Treated


See previous section for calculation with mortality data for the function
`calc_exposure`.

```{r}
mortdat.out[["EY0T1"]]
stopifnot(abs(mortdat.out$EY0T1 - 0.010176) < 1e-6)
```

### Standardization with a Parametric Exposure Model


The function `standexp` is used to standardized with a parametric exposure
model and the `glm` fit. It is the main function used in the chapter.

```{r file="lib\\fci_06-D_standexp.R"}

```

Alternatively the standardization could be done with `geeglm` from the `geepack`
package. For *those focused primarily on the risk difference*. See the 
explanation on section 6.2.2 on why `geeglm` is not really good for the
risk ratio.

The function is called `exp` in the book. We rename it `standexpgee` to be
more informative and avoid mix up with the much-used base R function `exp.`


```{r file="lib\\fci_06-E_standexpgee.R"}

```



#### What-if? Study {-}

First we do it using the `glm` fit

```{r}
whatif2.exp <- standexp(whatif2dat, formula = vl4 ~ A + lvlcont0)
# whatif2.exp
```

and compare with the author's


```{r}
comp <- data.frame(
  name = c("EY0", "EY1", "RD", "RR"),
  auth = c(0.36, 0.30, -0.06, 0.834),
  est = whatif2.exp$est[whatif2.exp$name %in% c("EY0", "EY1", "RD", "RR")])
stopifnot(sum(abs(comp$auth - comp$est)) < 0.01)
```



and the results are presented in table 6.9

```{r}
gt_measures(whatif2.exp, 
            title = "Table 6.9", 
            subtitle = "What-If Study<br>Exposure-model Standardization with <em>H = lvlcont0</em>")
```


then we use the `geeglm` from the `geepack` package fit for risk difference

```{r}
whatif2.expgee <- standexpgee(whatif2dat, formula = vl4 ~ A + lvlcont0)
# we don't use the risk ratio measures with this function
whatif2.expgee <- whatif2.expgee[!(whatif2.expgee$name %in% c("RR", "RR*", "OR")), ]
# whatif2.expgee
```

and the results are presented in table 6.9

```{r}
gt_measures(whatif2.expgee, 
            title = "Table 6.9 geeglm", 
            subtitle = "What-If Study<br>Exposure-model Standardization using <em>geeglm</em> wtih <em>H = lvlcont0</em>")
```


#### General Social Survey {-}

The `gssrcc` is defined in section 6.1.2 above. It is the `gss` data with
complete cases only.

The `standexp` function on page 119-120 of section 6.2.2 is not needed anymore
as `standexp` was created with parameters in the previous section. We just need
to run it as follows



```{r}
gssrcc.exp <- standexp(gssrcc, 
                        formula = trump ~ gthsedu + magthsedu + white + female + gt65)
# gssrcc.exp
```

and compare with the author's


```{r}
comp <- data.frame(
  name = c("EY0", "EY1", "RD", "RR"),
  auth = c(0.231, 0.272, 0.041, 1.176),
  est = gssrcc.exp$est[gssrcc.exp$name %in% c("EY0", "EY1", "RD", "RR")])
stopifnot(sum(abs(comp$auth - comp$est)) < 0.01)
```


and the results are presented in table 6.9

```{r}
gt_measures(gssrcc.exp, 
            title = "Table 6.10", 
            subtitle = "General Social Survey<br>Exposure-model Standardization<br>
            Effect of <em>More than High School Education</em> on <em>
            Voting for Trump</em>")
```


## Doubly Robust Standardization

The function `badstanddr` used for doubly robust standardization is defined
as follows

```{r file="lib\\fci_06-F_badstanddr.R"}

```


and using the What-if Study we obtain


```{r}
whatif2.dr <- badstanddr(whatif2dat, formula = vl4 ~ A + lvlcont0)
# whatif2.dr
```

and compare with the author's


```{r}
comp <- data.frame(
  name = c("EY0", "EY1", "RD", "RR"),
  auth = c(0.362, 0.300, -0.062, 0.830),
  est = whatif2.dr$est[whatif2.dr$name %in% c("EY0", "EY1", "RD", "RR")])
stopifnot(sum(abs(comp$auth - comp$est)) < 0.01)
```



and the results are presented in table 6.9

```{r}
gt_measures(whatif2.dr, 
            title = "Table 6.12", 
            subtitle = "What-If Study<br>Doubly Robust Standardizaion<br>
            Combining the Misspecified Outome Model of Table 6.11<br>
            and the Exposure Model of Table 6.9")
```

### Doubly Robust Standardization Simulation

The simulation of doubly robust standardization discussed at the end of 
section 6.3 in p. 126 to 130 is analyzed in an appendix at 
[Doubly Robust Simulation](#mc_standdr).

The results obtained by Brumback are close enough to what we have.  Here is a 
tableau of her results



```{r echo=FALSE}
the_estimators <- c("EYT0" = "Unadjusted", "EYT1" = "Unadjusted",
                    "EY0exp" = "Linear Exposure", "EY1exp" = "Linear Exposure",
                    "EY0exp2" = "Logistic Exposure", "EY1exp2" = "Logistic Exposure",
                    "EY0out" = "Overspecified Outcome", "EY1out" = "Overspecified Outcome",
                    "EY0dr" = "Doubly Robust", "EY1dr" = "Doubly Robust")
bb40 <- data.frame(
  ss = 40,
  estimator = names(the_estimators),
  description = the_estimators,
  mean = c(0.0076, 0.0042, 0.01, 0.0195, 0.0101, 0.0204, 
           0.01, 0.02, 0.01, 0.0197),
  sd = c(0.0015, 0.0012, 0.0021, 0.0127, 0.0021, 0.0064,
         0.0021, 0.0066, 0.0021, 0.0106),
  pval = c(0, 0, 0.92, 0.19, 0.42, 0.07, 0.79, 0.84, 0.82, 0.37)
)

bb100 <- data.frame(
  ss = 100,
  estimator = names(the_estimators),
  description = the_estimators,
  mean = c(0.0079, 0.0038, 0.01, 0.0196, 0.01, 0.02, 0.01, 0.02, 0.01, 0.029),
  sd = c(0.0016, 0.0012, 0.002, 0.0562, 0.002, 0.0068, 
         0.002, 0.0069, 0.002, 0.1891),
  pval = c(0, 0, 0.61, 0.81, 0.73, 0.96, 0.74, 0.74, 0.72, 0.14)
)

dft <- rbind(bb40, bb100) %>%
  select(ss, estimator, description, mean, sd, pval) %>%
  mutate(ss = paste("ss", ss, sep = "=")) %>%
  pivot_longer(cols = c("mean", "sd", "pval"), names_to = "stats", 
               values_to = "value") %>%
  mutate(value = ifelse(stats == "pval", round(value, 2), round(value, 4))) %>%
  unite(col = "heading", ss, stats, sep = "_") %>%
  pivot_wider(id_cols = c("estimator", "description"), names_from = "heading", 
              values_from = "value")

title <- "Table 6.13 and 6.14"
subtitle <- paste0("Sampling Distribution from Simulation", "<br>", 
                   "Investigating Small-Sample Robustness", "<br>", 
                   "True E(Y(0))=0.01, True E(Y(1))=0.02")
tbl <- gt::gt(dft) %>%
  gt_basic(title = title, subtitle = subtitle) %>%
  tab_spanner_delim(delim = "_", columns = everything(), split = "first") %>%
  cols_align(
    align = "left",
    columns = c("estimator", "description")
    ) %>%
  tab_style(
    style = cell_borders(sides = "left", color = "grey60",
                           weight = px(1.5), style = "solid"),
    locations = cells_body(columns = c("ss=100_mean"))
  ) %>%
  tab_style(
    style = cell_borders(sides = "left", color = "grey60",
                           weight = px(1.5), style = "solid"),
    locations = cells_column_labels(columns = c("ss=100_mean"))
  )
tbl
```




We use a sample size of only 1000 as in the book.

```{r}
nrep <- 1000
```

So here the simulation with $ss \in \{40, 100\}$

```{r}
message("This takes about 8 min. Load from file.")
# startTime <- Sys.time()
# mc.out <- mc_standdr(ss = c(40, 100), nrep = nrep)
# endTime <- Sys.time()
# print(endTime - startTime)
a_file <- file.path(dir_data, "chap06_mc_out.rds")
mc.out <- readRDS(file = a_file)
# saveRDS(mc.out, file = a_file)
```

and we compute the p-values

```{r}
mc.out <- mc.out %>%
    mutate(`T` = ifelse(grepl(pattern = "0", estimator), 0, 1),
         h0 = ifelse(`T` == 0, 0.01, 0.02),
         sdp = sd / sqrt(n),
         z = abs((mean - h0) / sdp),
         pval = 2 * (1 - pnorm(z))) %>%
  select(-sdp, -z)
# mc.out
```

and show the results in a table

```{r echo=FALSE}
dft <- mc.out %>%
  select(ss, estimator, mean, sd, pval) %>%
  mutate(ss = paste("ss", ss, sep = "=")) %>%
  pivot_longer(cols = c("mean", "sd", "pval"), names_to = "stats", 
               values_to = "value") %>%
  mutate(value = ifelse(stats == "pval", round(value, 2), round(value, 4))) %>%
  unite(col = "heading", ss, stats, sep = "_") %>%
  pivot_wider(id_cols = "estimator", names_from = "heading", 
              values_from = "value") %>%
  mutate(description = the_estimators[match(estimator, names(the_estimators))]) %>%
  relocate(description, .after = estimator)
# reorder the rows to match book's
dft <- dft[match(names(the_estimators), dft$estimator), ]

title <- "Table 6.13 and 6.14 <em>(by FL)</em>"
subtitle <- paste0("Sampling Distribution from Simulation", "<br>", 
                   "Investigating Small-Sample Robustness", "<br>", 
                   "True E(Y(0))=0.01, True E(Y(1))=0.02")
tbl <- gt::gt(dft) %>%
  gt_basic(title = title, subtitle = subtitle) %>%
  tab_spanner_delim(delim = "_", columns = everything(), split = "first") %>%
  cols_align(
    align = "left",
    columns = c("estimator", "description")
    ) %>%
  tab_style(
    style = cell_borders(sides = "left", color = "grey60",
                           weight = px(1.5), style = "solid"),
    locations = cells_body(columns = c("ss=100_mean"))
  ) %>%
  tab_style(
    style = cell_borders(sides = "left", color = "grey60",
                           weight = px(1.5), style = "solid"),
    locations = cells_column_labels(columns = c("ss=100_mean"))
  )
tbl
```

We will not reiterate the comments from Brumback as the results in the tableau 
just above confirms them.

A plot can however illustrate Brumback's main points. This ones shows the
estimates' mean with their 5% and 95% quantiles from the simulation.

```{r echo=FALSE}
mc.out %>%
  select(ss, estimator, mean, lower, upper) %>%
  mutate(ss = paste("ss", ss, sep = "=")) %>%
  ggplot(aes(x = mean, xmin = lower, xmax = upper, y = estimator, color = ss)) +
  geom_pointrange(position = position_dodge(width = 0.5)) +
  geom_vline(xintercept = c(0.01, 0.02), color = c("darkgreen", "darkorange"),
             linetype = "dashed", size = 1) + 
  ggrepel::geom_text_repel(aes(x = mean, y = estimator, label = round(mean, 2)), 
                           size = 3) +
  ggrepel::geom_text_repel(aes(x = lower, y = estimator, label = round(lower, 2)), 
                           size = 3) +
  ggrepel::geom_text_repel(aes(x = upper, y = estimator, label = round(upper, 2)), 
                           size = 3) +
  scale_x_continuous(breaks = seq(from = -0.1, to = 0.1, by = 0.01)) +
  theme_minimal() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = "bottom",
        legend.title = element_blank()) +
  labs(title = "Chap 6, section 6.3: Simulation of Standardization Methods",
       subtitle =
         sprintf("The mean with 2.5%% and 97.5%% quantiles. True E(Y(0)) = %.2f, True E(Y(1)) = %.2f.", 
                 0.01, 0.02),
       x = NULL, y = NULL)
```


## Exercises

### Exercise 1

```{r}
dataBRFSS <- brfss %>%
  filter(gt65 == 0)
```

```{r}
# message("This took ? min, so we load a saved file.")
# startTime <- Sys.time()
# brfss.out <- stand(dataBRFSS, formula = flushot ~ insured + female + whitenh + blacknh +
#                hisp + multinh + gthsedu + rural, R = 500)
# endTime <- Sys.time()
# print(endTime - startTime)
# a_file <- file.path(dir_data, "chap06_Ex1.rds")
# saveRDS(brfss.out, file = a_file)
# brfss.out <- readRDS(a_file)
```


```{r}
# brfss.out
```


